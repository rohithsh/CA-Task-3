{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de757968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dad3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/essay-corpus.json\"\n",
    "with open(path, 'r') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db02208e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "claims_df = data_df[['confirmation_bias','claims']].copy()\n",
    "claims_df['text_id'] = data_df['id'].copy()\n",
    "claims_df = claims_df.explode('claims')\n",
    "claims_df['span'] =  claims_df['claims'].apply(lambda x: x['span'])\n",
    "claims_df['claims'] =  claims_df['claims'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc47473",
   "metadata": {},
   "outputs": [],
   "source": [
    "majclaims_df = data_df[['id', 'confirmation_bias','major_claim']].copy()\n",
    "majclaims_df['text_id'] = data_df['id'].copy()\n",
    "majclaims_df = majclaims_df.explode('major_claim')\n",
    "majclaims_df['span'] =  majclaims_df['major_claim'].apply(lambda x: x['span'])\n",
    "majclaims_df['major_claim'] =  majclaims_df['major_claim'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8831bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "premises_df = data_df[['id', 'confirmation_bias','premises']].copy()\n",
    "premises_df['text_id'] = data_df['id'].copy()\n",
    "premises_df = premises_df.explode('premises')\n",
    "premises_df['span'] =  premises_df['premises'].apply(lambda x: x['span'])\n",
    "premises_df['premises'] =  premises_df['premises'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce00b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_df = data_df[['id', 'confirmation_bias','paragraphs']].copy()\n",
    "para_df = para_df.explode('paragraphs')\n",
    "para_df['sufficient'] =  para_df['paragraphs'].apply(lambda x: x['sufficient'])\n",
    "para_df['paragraphs'] =  para_df['paragraphs'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "760303b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/rohith/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def assign_scores(x):\n",
    "    res = analyzer.polarity_scores(x)\n",
    "    return list(res.values())\n",
    "\n",
    "premises_df[\"scores\"] =  premises_df[\"premises\"].apply(assign_scores)\n",
    "premises_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(premises_df.scores.tolist(),\n",
    "                                                         index = premises_df.index)\n",
    "majclaims_df[\"scores\"] =  majclaims_df[\"major_claim\"].apply(assign_scores)\n",
    "majclaims_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(majclaims_df.scores.tolist(),\n",
    "                                                         index = majclaims_df.index)\n",
    "\n",
    "claims_df[\"scores\"] =  claims_df[\"claims\"].apply(assign_scores)\n",
    "claims_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(claims_df.scores.tolist(),\n",
    "                                                         index = claims_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ebc21",
   "metadata": {},
   "source": [
    "premises_df_true = premises_df[premises_df['confirmation_bias']==True]\n",
    "avg_neg = premises_df_true['neg'].describe()\n",
    "avg_neu = premises_df_true['neu'].sum() / premises_df_true.shape[0]\n",
    "avg_pos = premises_df_true['pos'].sum() / premises_df_true.shape[0]\n",
    "avg_comp = premises_df_true['comp'].sum() / premises_df_true.shape[0]\n",
    "\n",
    "premises_df_false = premises_df[premises_df['confirmation_bias']==False]\n",
    "avg_neg_1 = premises_df_false['neg'].describe()\n",
    "avg_neu_1 = premises_df_false['neu'].sum() / premises_df_true.shape[0]\n",
    "avg_pos_1 = premises_df_false['pos'].sum() / premises_df_true.shape[0]\n",
    "avg_comp_1 = premises_df_false['comp'].sum() / premises_df_true.shape[0]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(premises_df_false['comp'], premises_df_false['neg'], color = 'red')\n",
    "ax.scatter(premises_df_true['comp'], premises_df_true['neg'], color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122d7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = claims_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum()\n",
    "maj_claims = majclaims_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum() \n",
    "premises = premises_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9b45844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(claims, maj_claims, on='text_id')\n",
    "df2 = pd.merge(df1, premises, on='text_id')\n",
    "final_df = pd.merge(df2, data_df[['id', 'confirmation_bias']], left_on='text_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "742f7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['neg'] = (final_df['neg'] + final_df['neg_x'] + final_df['neg_y']) / 3\n",
    "final_df['pos'] = (final_df['pos'] + final_df['pos_x'] + final_df['pos_y']) / 3\n",
    "final_df['neu'] = (final_df['neu'] + final_df['neu_x'] + final_df['neu_y']) / 3\n",
    "final_df['comp'] = (final_df['comp'] + final_df['comp_x'] + final_df['comp_y']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae75e12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#final_df = final_df.drop(['neg_x','neg_y', 'pos_x', 'pos_y', 'neu_x', 'neu_y', 'comp_x', 'comp_y'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f8d61fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7461139896373057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x = final_df[['neg','pos','neu','comp']]\n",
    "y = final_df['confirmation_bias']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=109)\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(metrics.f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44afbd8",
   "metadata": {},
   "source": [
    "Pending:\n",
    "1. Hyper-parameter Tuning\n",
    "2. Cross Validation\n",
    "3. Using proper test/train data\n",
    "4. Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3441ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75757576 0.7761194  0.76923077 0.76923077 0.76923077 0.76923077\n",
      " 0.76923077 0.76923077 0.76923077 0.76923077]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, x, y,scoring=\"f1\",cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8597493",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
