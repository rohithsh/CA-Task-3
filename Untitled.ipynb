{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de757968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9dad3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/essay-corpus.json\"\n",
    "with open(path, 'r', encoding = 'latin-1') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db02208e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "claims_df = data_df[['confirmation_bias','claims']].copy()\n",
    "claims_df['text_id'] = data_df['id'].copy()\n",
    "claims_df = claims_df.explode('claims')\n",
    "claims_df['span'] =  claims_df['claims'].apply(lambda x: x['span'])\n",
    "claims_df['claims'] =  claims_df['claims'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcc47473",
   "metadata": {},
   "outputs": [],
   "source": [
    "majclaims_df = data_df[['id', 'confirmation_bias','major_claim']].copy()\n",
    "majclaims_df['text_id'] = data_df['id'].copy()\n",
    "majclaims_df = majclaims_df.explode('major_claim')\n",
    "majclaims_df['span'] =  majclaims_df['major_claim'].apply(lambda x: x['span'])\n",
    "majclaims_df['major_claim'] =  majclaims_df['major_claim'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8831bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "premises_df = data_df[['id', 'confirmation_bias','premises']].copy()\n",
    "premises_df['text_id'] = data_df['id'].copy()\n",
    "premises_df = premises_df.explode('premises')\n",
    "premises_df['span'] =  premises_df['premises'].apply(lambda x: x['span'])\n",
    "premises_df['premises'] =  premises_df['premises'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce00b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_df = data_df[['id', 'confirmation_bias','paragraphs']].copy()\n",
    "para_df = para_df.explode('paragraphs')\n",
    "para_df['sufficient'] =  para_df['paragraphs'].apply(lambda x: x['sufficient'])\n",
    "para_df['paragraphs'] =  para_df['paragraphs'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "760303b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Akshita\\AppData\\Roaming\\nltk_data...\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def assign_scores(x):\n",
    "    res = analyzer.polarity_scores(x)\n",
    "    return list(res.values())\n",
    "\n",
    "premises_df[\"scores\"] =  premises_df[\"premises\"].apply(assign_scores)\n",
    "premises_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(premises_df.scores.tolist(),\n",
    "                                                         index = premises_df.index)\n",
    "majclaims_df[\"scores\"] =  majclaims_df[\"major_claim\"].apply(assign_scores)\n",
    "majclaims_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(majclaims_df.scores.tolist(),\n",
    "                                                         index = majclaims_df.index)\n",
    "\n",
    "claims_df[\"scores\"] =  claims_df[\"claims\"].apply(assign_scores)\n",
    "claims_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(claims_df.scores.tolist(),\n",
    "                                                         index = claims_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ebc21",
   "metadata": {},
   "source": [
    "premises_df_true = premises_df[premises_df['confirmation_bias']==True]\n",
    "avg_neg = premises_df_true['neg'].describe()\n",
    "avg_neu = premises_df_true['neu'].sum() / premises_df_true.shape[0]\n",
    "avg_pos = premises_df_true['pos'].sum() / premises_df_true.shape[0]\n",
    "avg_comp = premises_df_true['comp'].sum() / premises_df_true.shape[0]\n",
    "\n",
    "premises_df_false = premises_df[premises_df['confirmation_bias']==False]\n",
    "avg_neg_1 = premises_df_false['neg'].describe()\n",
    "avg_neu_1 = premises_df_false['neu'].sum() / premises_df_true.shape[0]\n",
    "avg_pos_1 = premises_df_false['pos'].sum() / premises_df_true.shape[0]\n",
    "avg_comp_1 = premises_df_false['comp'].sum() / premises_df_true.shape[0]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(premises_df_false['comp'], premises_df_false['neg'], color = 'red')\n",
    "ax.scatter(premises_df_true['comp'], premises_df_true['neg'], color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "122d7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = claims_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum()\n",
    "maj_claims = majclaims_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum() \n",
    "premises = premises_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d9b45844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(claims, maj_claims, on='text_id')\n",
    "df2 = pd.merge(df1, premises, on='text_id')\n",
    "final_df = pd.merge(df2, data_df[['id', 'confirmation_bias']], left_on='text_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "742f7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['neg'] = (final_df['neg'] + final_df['neg_x'] + final_df['neg_y']) / 3\n",
    "final_df['pos'] = (final_df['pos'] + final_df['pos_x'] + final_df['pos_y']) / 3\n",
    "final_df['neu'] = (final_df['neu'] + final_df['neu_x'] + final_df['neu_y']) / 3\n",
    "final_df['comp'] = (final_df['comp'] + final_df['comp_x'] + final_df['comp_y']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae75e12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#final_df = final_df.drop(['neg_x','neg_y', 'pos_x', 'pos_y', 'neu_x', 'neu_y', 'comp_x', 'comp_y'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8d61fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00        49\n",
      "        True       0.60      1.00      0.75        72\n",
      "\n",
      "    accuracy                           0.60       121\n",
      "   macro avg       0.30      0.50      0.37       121\n",
      "weighted avg       0.35      0.60      0.44       121\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "x = final_df[['neg','pos','neu','comp']]\n",
    "y = final_df['confirmation_bias']\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.3,random_state=109)\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "# print(\"F1-score\",metrics.f1_score(y_test, y_pred))\n",
    "# print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44afbd8",
   "metadata": {},
   "source": [
    "Pending:\n",
    "1. Hyper-parameter Tuning\n",
    "2. Cross Validation\n",
    "3. Using proper test/train data\n",
    "4. Documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3441ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75757576 0.7761194  0.76923077 0.76923077 0.76923077 0.76923077\n",
      " 0.76923077 0.76923077 0.76923077 0.76923077]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(clf, x, y,scoring=\"f1\",cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd392f",
   "metadata": {},
   "source": [
    "Hyper Parameter Tuning - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f8597493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 15 candidates, totalling 450 fits\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    " \n",
    "param_grid = {'C': [50, 10, 1.0, 0.1, 0.01],\n",
    "              'gamma': ['scale'],\n",
    "              'kernel': ['poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0, refit = True, verbose = 3)\n",
    "\n",
    "grid_result = grid_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cf00cd7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.643021 using {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.634688 (0.019106) with: {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.643021 (0.027007) with: {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.501642 (0.100132) with: {'C': 50, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.637069 (0.011966) with: {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.643021 (0.023650) with: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.504064 (0.099083) with: {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.637069 (0.011966) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.637069 (0.011966) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.511248 (0.104078) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.637069 (0.011966) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.637069 (0.011966) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.637069 (0.011966) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.637069 (0.011966) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.637069 (0.011966) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.637069 (0.011966) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n"
     ]
    }
   ],
   "source": [
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e3571791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9202061f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=50)\n"
     ]
    }
   ],
   "source": [
    "print(grid_result.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "29dda9cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00        49\n",
      "        True       0.59      0.97      0.73        72\n",
      "\n",
      "    accuracy                           0.58       121\n",
      "   macro avg       0.29      0.49      0.37       121\n",
      "weighted avg       0.35      0.58      0.44       121\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grid_predictions = grid_result.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
