{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de757968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dad3b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"data/essay-corpus.json\"\n",
    "with open(path, 'r', encoding = 'latin-1') as f:\n",
    "  data = json.load(f)\n",
    "\n",
    "data_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db02208e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "claims_df = data_df[['confirmation_bias','claims']].copy()\n",
    "claims_df['text_id'] = data_df['id'].copy()\n",
    "claims_df = claims_df.explode('claims')\n",
    "claims_df['span'] =  claims_df['claims'].apply(lambda x: x['span'])\n",
    "claims_df['claims'] =  claims_df['claims'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bcc47473",
   "metadata": {},
   "outputs": [],
   "source": [
    "majclaims_df = data_df[['id', 'confirmation_bias','major_claim']].copy()\n",
    "majclaims_df['text_id'] = data_df['id'].copy()\n",
    "majclaims_df = majclaims_df.explode('major_claim')\n",
    "majclaims_df['span'] =  majclaims_df['major_claim'].apply(lambda x: x['span'])\n",
    "majclaims_df['major_claim'] =  majclaims_df['major_claim'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8831bc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "premises_df = data_df[['id', 'confirmation_bias','premises']].copy()\n",
    "premises_df['text_id'] = data_df['id'].copy()\n",
    "premises_df = premises_df.explode('premises')\n",
    "premises_df['span'] =  premises_df['premises'].apply(lambda x: x['span'])\n",
    "premises_df['premises'] =  premises_df['premises'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce00b782",
   "metadata": {},
   "outputs": [],
   "source": [
    "para_df = data_df[['id', 'confirmation_bias','paragraphs']].copy()\n",
    "para_df = para_df.explode('paragraphs')\n",
    "para_df['sufficient'] =  para_df['paragraphs'].apply(lambda x: x['sufficient'])\n",
    "para_df['paragraphs'] =  para_df['paragraphs'].apply(lambda x: x['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "760303b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/rohith/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "def assign_scores(x):\n",
    "    res = analyzer.polarity_scores(x)\n",
    "    return list(res.values())\n",
    "\n",
    "premises_df[\"scores\"] =  premises_df[\"premises\"].apply(assign_scores)\n",
    "premises_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(premises_df.scores.tolist(),\n",
    "                                                         index = premises_df.index)\n",
    "majclaims_df[\"scores\"] =  majclaims_df[\"major_claim\"].apply(assign_scores)\n",
    "majclaims_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(majclaims_df.scores.tolist(),\n",
    "                                                         index = majclaims_df.index)\n",
    "\n",
    "claims_df[\"scores\"] =  claims_df[\"claims\"].apply(assign_scores)\n",
    "claims_df[['neg', 'neu', 'pos', 'comp']] = pd.DataFrame(claims_df.scores.tolist(),\n",
    "                                                         index = claims_df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425ebc21",
   "metadata": {},
   "source": [
    "premises_df_true = premises_df[premises_df['confirmation_bias']==True]\n",
    "avg_neg = premises_df_true['neg'].describe()\n",
    "avg_neu = premises_df_true['neu'].sum() / premises_df_true.shape[0]\n",
    "avg_pos = premises_df_true['pos'].sum() / premises_df_true.shape[0]\n",
    "avg_comp = premises_df_true['comp'].sum() / premises_df_true.shape[0]\n",
    "\n",
    "premises_df_false = premises_df[premises_df['confirmation_bias']==False]\n",
    "avg_neg_1 = premises_df_false['neg'].describe()\n",
    "avg_neu_1 = premises_df_false['neu'].sum() / premises_df_true.shape[0]\n",
    "avg_pos_1 = premises_df_false['pos'].sum() / premises_df_true.shape[0]\n",
    "avg_comp_1 = premises_df_false['comp'].sum() / premises_df_true.shape[0]\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(premises_df_false['comp'], premises_df_false['neg'], color = 'red')\n",
    "ax.scatter(premises_df_true['comp'], premises_df_true['neg'], color = 'blue')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "122d7ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "claims = claims_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum()\n",
    "maj_claims = majclaims_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum() \n",
    "premises = premises_df[['text_id', 'neg', 'neu', 'pos', 'comp']].groupby(['text_id']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b45844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.merge(claims, maj_claims, on='text_id')\n",
    "df2 = pd.merge(df1, premises, on='text_id')\n",
    "final_df = pd.merge(df2, data_df[['id', 'confirmation_bias']], left_on='text_id', right_on='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "742f7b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df['neg'] = (final_df['neg'] + final_df['neg_x'] + final_df['neg_y']) / 3\n",
    "final_df['pos'] = (final_df['pos'] + final_df['pos_x'] + final_df['pos_y']) / 3\n",
    "final_df['neu'] = (final_df['neu'] + final_df['neu_x'] + final_df['neu_y']) / 3\n",
    "final_df['comp'] = (final_df['comp'] + final_df['comp_x'] + final_df['comp_y']) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ae75e12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#final_df = final_df.drop(['neg_x','neg_y', 'pos_x', 'pos_y', 'neu_x', 'neu_y', 'comp_x', 'comp_y'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5bb12482",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file = pd.read_csv(\"data/train-test-split.csv\", sep=\";\")\n",
    "test_file['id'] = test_file.index + 1\n",
    "final_df = pd.merge(final_df, test_file, on='id')\n",
    "train = final_df[final_df['SET']=='TRAIN'][['neg','pos','neu','comp', 'confirmation_bias']]\n",
    "test = final_df[final_df['SET']=='TEST'][['neg','pos','neu','comp', 'confirmation_bias']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8d61fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score 0.7786259541984732\n"
     ]
    }
   ],
   "source": [
    "X_train = train[['neg','pos','neu','comp']]\n",
    "y_train = train['confirmation_bias']\n",
    "X_test = test[['neg','pos','neu','comp']]\n",
    "y_test = test['confirmation_bias']\n",
    "\n",
    "from sklearn import svm, metrics\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "print(\"F1-score\",metrics.f1_score(y_test, y_pred))\n",
    "#print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\n",
    "# print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n",
    "# print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n",
    "#print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39950383",
   "metadata": {},
   "source": [
    "Cross Validation - 10 fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3441ad1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75757576 0.7761194  0.76923077 0.76923077 0.76923077 0.76923077\n",
      " 0.76923077 0.76923077 0.76923077 0.76923077]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "x = final_df[['neg','pos','neu','comp']]\n",
    "y = final_df['confirmation_bias']\n",
    "scores = cross_val_score(clf, x, y,scoring=\"f1\",cv=10)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99dd392f",
   "metadata": {},
   "source": [
    "Hyper Parameter Tuning - Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0db3c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 30 folds for each of 15 candidates, totalling 450 fits\n",
      "Best: 0.621212 using {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.621212 (0.007576) with: {'C': 50, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.614015 (0.018685) with: {'C': 50, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.524085 (0.081435) with: {'C': 50, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.621212 (0.007576) with: {'C': 10, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.621212 (0.007576) with: {'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.524085 (0.080227) with: {'C': 10, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.621212 (0.007576) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.621212 (0.007576) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.526105 (0.068865) with: {'C': 1.0, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.621212 (0.007576) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.621212 (0.007576) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.621212 (0.007576) with: {'C': 0.1, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "0.621212 (0.007576) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "0.621212 (0.007576) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'rbf'}\n",
      "0.621212 (0.007576) with: {'C': 0.01, 'gamma': 'scale', 'kernel': 'sigmoid'}\n",
      "{'C': 50, 'gamma': 'scale', 'kernel': 'poly'}\n",
      "SVC(C=50, kernel='poly')\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00        29\n",
      "        True       0.63      0.98      0.77        51\n",
      "\n",
      "    accuracy                           0.62        80\n",
      "   macro avg       0.32      0.49      0.38        80\n",
      "weighted avg       0.40      0.62      0.49        80\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    " \n",
    "param_grid = {'C': [50, 10, 1.0, 0.1, 0.01],\n",
    "              'gamma': ['scale'],\n",
    "              'kernel': ['poly', 'rbf', 'sigmoid']}\n",
    "\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(svm.SVC(), param_grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0, refit = True, verbose = 3)\n",
    "grid_result = grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "print(grid_result.best_params_)\n",
    "print(grid_result.best_estimator_)\n",
    "grid_predictions = grid_result.predict(X_test)\n",
    "print(classification_report(y_test, grid_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
